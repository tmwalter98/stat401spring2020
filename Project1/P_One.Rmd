---
title: "R Notebook"
output: html_notebook
---
```{r}
# Problem 1.1
# dbinom gives the density of a function of a binomial probability
# pbinom gives the probability distribution of a function of a binomial probability
# barplot plots bar graphs

# Problem 1.2a
n <-5
p <- 0.1
barplot(dbinom(x=0:n, size=n, prob=p)) #(5, 0.1)

n <- 10
p <- 0.1
barplot(dbinom(x=0:n, size=n, prob=p)) #(10, 0.1)

n <- 20
p <- 0.1
barplot(dbinom(x=0:n, size=n, prob=p)) #(20, 0.1)

n <- 30
p <- 0.1
barplot(dbinom(x=0:n, size=n, prob=p)) #(30, 0.1)

n <- 50
p <- 0.1
barplot(dbinom(x=0:n, size=n, prob=p)) #(50, 0.1)

# Problem 1.2b
n <- 5
p <- 0.6
barplot(dbinom(x=0:n, size=n, prob=p)) #(5, 0.6)

n <- 10
p <- 0.6
barplot(dbinom(x=0:n, size=n, prob=p)) #(10, 0.6)

n <- 15
p <- 0.6
barplot(dbinom(x=0:n, size=n, prob=p)) #(15, 0.6)

n <- 30
p <- 0.6
barplot(dbinom(x=0:n, size=n, prob=p)) #(30, 0.6)

# Problem 1.2c
n <- 5
p <- 0.9
barplot(dbinom(x=0:n, size=n, prob=p)) #(5, 0.9)

n <- 10
p <- 0.9
barplot(dbinom(x=0:n, size=n, prob=p)) #(10, 0.9)

n <- 20
p <- 0.9
barplot(dbinom(x=0:n, size=n, prob=p)) #(20, 0.9)

n <- 30
p <- 0.9
barplot(dbinom(x=0:n, size=n, prob=p)) #(30, 0.9)

n <- 50
p <- 0.9
barplot(dbinom(x=0:n, size=n, prob=p)) #(50, 0.9)

# Problem 1.3
# Used n=20, as there was no given n
barplot(dpois(x=0:20, 2, log=FALSE)) # Created Poisson Barplots for each different lambda

barplot(dpois(x=0:20, 4, log=FALSE))

barplot(dpois(x=0:20, 5, log=FALSE))

barplot(dpois(x=0:20, 10, log=FALSE))

barplot(dpois(x=0:20, 20, log=FALSE))

barplot(dpois(x=0:20, 30, log=FALSE))

barplot(dpois(x=0:20, 50, log=FALSE))

# Problem 1.4
# The more lambda increases, the more skewed it is the the left.
```
```{r}
library(matrixStats) # Import library to use colStats
# Problem 2
p <- matrix(c(2,0.3,4,0.35,6,0.25,10,0.1),ncol=4)
# Created a matrix to store the values, and to access them easier

# Problem 2.1
mu <- 0

for (c in 1:ncol(p)) # Iterate through the columns (x)
    mu <- (mu + (p[1,c]*p[2,c])) # Multiply them with the corresponding p(x) and add it to previous mu

print(mu)

# Problem 2.2
std <- 0

for (c in 1:ncol(p)) # Used the standard deviation equation of sqrt(((x-mu)^2)*p(x))
  std <- (std + ((p[1,c]-mu)^2)*p[2,c])

print(sqrt(std))

# Problem 2.3 & 2.4a
r2 <- replicate(8000, rnorm(2)) # Used replicate to simulate 8000 trials of size n
r6 <- replicate(8000, rnorm(6))
r12 <- replicate(8000, rnorm(12))
r20 <- replicate(8000, rnorm(20))
r100 <- replicate(8000, rnorm(100))
r150 <- replicate(8000, rnorm(150))

# Problem 2.4b
mu2 <- colMeans(r2) # Used colMeans to compute the Means of the trials
mu6 <- colMeans(r6)
mu12 <- colMeans(r12)
mu20 <- colMeans(r20)
mu100 <- colMeans(r100)
mu150 <- colMeans(r150)

std2 <- colSds(r2) # Did a similar process for the Standard Deviations
std6 <- colSds(r6)
std12 <- colSds(r12)
std20 <- colSds(r20)
std100 <- colSds(r100)
std150 <- colSds(r150)

# Problem 2.4c
hist(r2) # Graphed a histogram of the trials that were replicated
hist(r6)
hist(r12)
hist(r20)
hist(r100)
hist(r150)

# Problem 2.4e
# The increase of the sample size causes the sample mean to become smaller and the distribution seems to get a little wider.
# The increasing replicates made the approximation more accurate because there was more data, which can be backed by using the CLT.
```
```{r}
library(matrixStats) # Import library to use colStats

# Problem 3.1
r5 <- replicate(10000, rnorm(5, mean=10, sd=2))
print(mean(colMeans(r5))) # Getting average Mean of experiments for overall Mean of all the simulations
print(mean(colSds(r5))) # Getting average Std of experiments for overall Std of all the simulations

r10 <- replicate(10000, rnorm(10, mean=10, sd=2)) # Repeat for the rest of the different n values
print(mean(colMeans(r10)))
print(mean(colSds(r10)))

r15 <- replicate(10000, rnorm(15, mean=10, sd=2))
print(mean(colMeans(r15)))
print(mean(colSds(r15)))

r25 <- replicate(10000, rnorm(25, mean=10, sd=2))
print(mean(colMeans(r25)))
print(mean(colSds(r25)))

r30 <- replicate(10000, rnorm(30, mean=10, sd=2))
print(mean(colMeans(r30)))
print(mean(colSds(r30)))

r50 <- replicate(10000, rnorm(50, mean=10, sd=2))
print(mean(colMeans(r50)))
print(mean(colSds(r50)))

r100 <- replicate(10000, rnorm(100, mean=10, sd=2))
print(mean(colMeans(r100)))
print(mean(colSds(r100)))

# The higher the number of random samples gets, the closer the Mean and standard Deviation are to the population Mean and Standard Deviation, which we know is 10 and 2 respectively.

# Problem 3.2
r5 <- replicate(10000, rexp(5,2))
print(mean(colMeans(r5))) # Getting average Mean of experiments
print(mean(colSds(r5))) # Getting average Std of experiments

r10 <- replicate(10000, rexp(10,2)) # Repeat for the different parameters
print(mean(colMeans(r10)))
print(mean(colSds(r10)))

r15 <- replicate(10000, rexp(15,2))
print(mean(colMeans(r15)))
print(mean(colSds(r15)))

r25 <- replicate(10000, rexp(25,2))
print(mean(colMeans(r25)))
print(mean(colSds(r25)))

r30 <- replicate(10000, rexp(30,2))
print(mean(colMeans(r30)))
print(mean(colSds(r30)))

r50 <- replicate(10000, rexp(50,2))
print(mean(colMeans(r50)))
print(mean(colSds(r50)))

r100 <- replicate(10000, rexp(100,2))
print(mean(colMeans(r100)))
print(mean(colSds(r100)))

# As the sample size increases, the Mean and Standard Deviation of an exponential distribution get closer to what the population Mean and Standard Deviation is, which we know of as (1/lambda) or 0.5 in this example.

# Problem 3.3
r5 <- replicate(10000, rgamma(5,2,3))
print(mean(colMeans(r5))) # Getting average Mean of experiments
print(mean(colSds(r5))) # Getting average Std of experiments

r10 <- replicate(10000, rgamma(10,2,3)) # Repeat for different sample sizes
print(mean(colMeans(r10)))
print(mean(colSds(r10)))

r15 <- replicate(10000, rgamma(15,2,3))
print(mean(colMeans(r15)))
print(mean(colSds(r15)))

r25 <- replicate(10000, rgamma(25,2,3))
print(mean(colMeans(r25)))
print(mean(colSds(r25)))

r30 <- replicate(10000, rgamma(30,2,3))
print(mean(colMeans(r30)))
print(mean(colSds(r30)))

r50 <- replicate(10000, rgamma(50,2,3))
print(mean(colMeans(r50)))
print(mean(colSds(r50)))

r100 <- replicate(10000, rgamma(100,2,3))
print(mean(colMeans(r100)))
print(mean(colSds(r100)))

# As the sample size increases, the Mean and Standard Deviation of a Gamma Distribution gets closer to the population's Mean and Standard Deviation, which in this case is calculated as (2/3) and (sqrt(2/9)) for Mean and Standard Deviation respectively.

# Problem 3.4
r5 <- replicate(10000, rchisq(5,5))
print(mean(colMeans(r5))) # Getting average Mean of experiments
print(mean(colSds(r5))) # Getting average Std of experiments

r10 <- replicate(10000, rchisq(10,5)) # Repeat for the different sample sizes
print(mean(colMeans(r10)))
print(mean(colSds(r10)))

r15 <- replicate(10000, rchisq(15,5))
print(mean(colMeans(r15)))
print(mean(colSds(r15)))

r25 <- replicate(10000, rchisq(25,5))
print(mean(colMeans(r25)))
print(mean(colSds(r25)))

r30 <- replicate(10000, rchisq(30,5))
print(mean(colMeans(r30)))
print(mean(colSds(r30)))

r50 <- replicate(10000, rchisq(50,5))
print(mean(colMeans(r50)))
print(mean(colSds(r50)))

r100 <- replicate(10000, rchisq(100,5))
print(mean(colMeans(r100)))
print(mean(colSds(r100)))

# As the sample size increases, the Mean and Standard Deviation of a Chi-Squared distribution gets closer to the population's Mean and Standard Deviation, which in this case should be 5 and sqrt(10) respectively.
```


